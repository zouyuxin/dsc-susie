# SuSiE demonstrated in DSC

## Goal

This is a Dynamic Statistical Comparison for testing SuSiE performance given a design matrix `X` from real data, e.g. GTEx, single cell, or GSEA data.

Our goal is to investigate how SuSiE performs (see "evaluation criteria" below) in the context of different X structures.

## Data 

### GTEx gene expression data

Gene expression from two tissues: whole blood and brain cells. Design matrix `X` is a gene expression matrix from 755 whole blood and 439 brain cell samples on 1000 genes. 

### Single cell gene expression data

Gene expression of two types of hard-to-distinguished cells. Design matrix `X` has 600 regulatory T cells and 600 memory T cells on 1000 genes.

### GSEA gene-set data

Gene-set / pathway annotation of genes. Design matrix `X` has 1200 genes on 1000 pathways. Each column is a gene-set / pathway of binary coding where `1` indicates the corresponding row (gene) is in the gene-set, `0` otherwise.

### Random data

Random data are a 1200 by 1000 matrix, each entry of which is randomly generated from `rnorm(0,1)`.


### GTEx genotype data

Design matrix `X` is a 574 by 1001 matrix. [FIXME, what is n and p] 

## Simulation

We simulate 50 datasets. For each dataset, we simulate a gaussian `y` under various number of causal variables and total percentage of variance explained (PVE).

## Analysis methods

We run SuSiE to investigate various questions of interest. For instance, performance on different dataset, factors that impact power, choice of priors, and so on. See "Investigations" section below.

## Performance evaluation criteria

We evaluate SuSiE performance by the following four numerical values:

  - **Power**: number of confidence sets (CS) that contain at least one true effect, divided by number of true effects
  - **FDR**: an estimate for false discovery rate, 1 - (number of CS that contain at least one true effect devided by number of CS reported)  

  - **CS number**: number of CS reported

  - **CS size**: median size of CS reported
  
  - **CS purity**: average "purity" of CS, an indication of correlation of variables within CS 
  
  - **top hit rate**: define "top hit" as a true effect that receives a SuSiE posterior inclusion probability (PIP) being the highest PIP among all variables in the same reported CS. Top hit rate is then given by the number of top hit divided by the number of CS that contains at least one true effect.

## Investigations

[FIXME: add links]

### GTEx gene expression data

  - Power of SuSiE
    - [one non-zero effects](analysis/gtex1.html)
    - multiple non-zero effects

  - Choice of prior
    - one non-zero effect 
    - two non-zero effects

  - Large number of causal variables
    - performance of 200 non-zero effects

## DSC instructions

### General instructions

The main DSC file is `benchmarks.dsc`. To see what is available:

```
./benchmark.dsc -h
```

before running, 
```
rm -Rf benchmark.scripts.html benchmark.html benchmark

```

and to run the benchmark for 50 datasets:

```
dsc benchmark.dsc --replicate 50
```

Or to run a minimal test benchmark, e.g.
```
dsc benchmark.dsc --truncate
```

To run on the cluster:

```
dsc benchmark.dsc --host midway.yml --replicate 50 -c 40 
```

### Input `X`

To input a customized design matrix `X`, please go to `benchmark.dsc`. At the bottom, change the `pathX` to the path of your matrix `X` as you want. 
